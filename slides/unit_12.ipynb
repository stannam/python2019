{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Handling Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, I really enjoyed the food :) #happy!\n",
      "Hey I really enjoyed the food  happy\n"
     ]
    }
   ],
   "source": [
    "tweet=\"Hey, I really enjoyed the food :) #happy!\"\n",
    "punc=string.punctuation\n",
    "cleaned=tweet.translate(string.maketrans(\"\",\"\"), punc)\n",
    "print(tweet)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xef\\xbb\\xbfThe Project Gutenberg EBook of The Complete Works of William Shakespeare, by\\r\\n', 'William Shakespeare\\r\\n', '\\r\\n', 'This eBook is for the use of anyone anywhere at no cost and with\\r\\n', 'almost no restrictions whatsoever.  You may copy it, give it away or\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "my_text=open(\"shakespeare.txt\", \"r\").readlines()\n",
    "print(my_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"of\" occurs \"7\" times.\n",
      "The word \"the\" occurs \"7\" times.\n",
      "The word \"ebook\" occurs \"6\" times.\n",
      "The word \"shakespeare\" occurs \"5\" times.\n",
      "The word \"this\" occurs \"5\" times.\n",
      "The word \"william\" occurs \"4\" times.\n",
      "The word \"gutenberg\" occurs \"4\" times.\n",
      "The word \"project\" occurs \"4\" times.\n",
      "The word \"it\" occurs \"3\" times.\n",
      "The word \"complete\" occurs \"3\" times.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punc=string.punctuation\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_dict(sentences):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "    input: @sentences: a list of sentences\n",
    "    returns: a dictionary of the words in the sentences.\n",
    "             dict key is a word and value is word frequency\n",
    "    \"\"\"\n",
    "    word_freq=defaultdict(int)\n",
    "    for sent in sentences:\n",
    "        sent= sent.translate(string.maketrans(\"\",\"\"), punc)\n",
    "        words=sent.lower().split()\n",
    "        for w in words:\n",
    "            word_freq[w]+=1\n",
    "    return word_freq\n",
    "###############\n",
    "lines=open(\"shakespeare.txt\", \"r\").readlines()\n",
    "sentences=lines[:30]\n",
    "freqs=get_dict(sentences)\n",
    "# This will sort by count/value of the \"freqs\" dictionary in reverse order such that the highest values occur first\n",
    "d=sorted(freqs.items(), key = lambda x: x[1], reverse=True) # \"d\" is now a list of tuples!\n",
    "for i in d:\n",
    "    # For readability let's assign each item in the tuple to a meaningfully named variable\n",
    "    w=i[0]\n",
    "    freq=i[-1]\n",
    "    if freq > 2:\n",
    "        print(\"The word \\\"{}\\\" occurs \\\"{}\\\" times.\").format(w, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This will write freqs to a file\n",
    "lines=open(\"shakespeare.txt\", \"r\").readlines()\n",
    "# We only take the top 1000 lines\n",
    "#sentences=lines[:1000]\n",
    "#freqs=get_dict(sentences)\n",
    "freqs=get_dict(lines)\n",
    "d=sorted(freqs.items(), key = lambda x: x[1], reverse=True)\n",
    "word_freqs=open(\"./new_word_list.txt\", \"w\")\n",
    "for i in d:\n",
    "    # For readability\n",
    "    w=i[0]\n",
    "    freq=i[-1]\n",
    "    word_freqs.write(w+\"\\t\"+str(freq)+\"\\n\")\n",
    "    \n",
    "word_freqs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Take a look at the preface here: http://www.nltk.org/book/ch00.html\n",
    "* This tutorial is based on Python 2.7, but it shouldn't be an issue to write the same code for Python 3 as the differences are minimal so long as the tutorial is concerned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the free power opportunity fellow opinions colleges peace gangs\n",
      "judgments consent noblest ideas colors fidelity unquestionable worship\n",
      "discipline industrious just\n"
     ]
    }
   ],
   "source": [
    "text4.similar(\"patriotic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every_citizen and_and our_citizens\n"
     ]
    }
   ],
   "source": [
    "# Let's look at common contexts of two words:\n",
    "text4.common_contexts([\"patriotic\", \"free\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('man', 102)\n",
      "('woman', 3)\n",
      "('father', 4)\n",
      "('mother', 4)\n"
     ]
    }
   ],
   "source": [
    "# Counting word frequencies:\n",
    "words=[\"man\", \"woman\", \"father\", \"mother\"]\n",
    "for w in words:\n",
    "    print(w, text4.count(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "# Collocations\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'happy']\n",
      "['we', \"'re\", 'playing', 'tennis']\n",
      "['we', \"'ll\", 'study']\n",
      "['They', \"'ve\", 'cooked']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization with NLTK:\n",
    "import nltk\n",
    "raw=[\"I'm happy\", \"we're playing tennis\", \"we'll study\", \"They've cooked\"]\n",
    "for i in raw:\n",
    "    tokens=nltk.word_tokenize(i)\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's look at the text4: Inaugural Address Corpus\n",
    "* NLTK can show a word in context, called a concordance (with a given text window size):\n",
    "* **width:** a parameter forthe window size of surrounding character context\n",
    "* **lines:** a parameter for the number of lines returned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 66 matches:\n",
      "ons may come . The Negroes are now Americans . Their ancestors came here years \n",
      " not . And yet we are not the less Americans on that account . We shall be the \n",
      "em now secure ; and there comes to Americans the profound assurance that our re\n",
      "d me . I am certain that my fellow Americans expect that on my induction into t\n",
      "urricanes of disaster . In this we Americans were discovering no wholly new tru\n",
      "freedom is an ebbing tide . But we Americans know that this is not true . Eight\n",
      "re not content to stand still . As Americans , we go forward , in the service o\n",
      "be simple and its words brief . We Americans of today , together with our allie\n",
      "charge of this responsibility , we Americans know and we observe the difference\n",
      "in of trading honor for security . Americans , indeed all free men , remember t\n"
     ]
    }
   ],
   "source": [
    "text4.concordance(\"Americans\", width=80, lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "[u'\\ufeffthe', u'project', u'gutenberg', u'ebook', u'of', u'the', u'complete', u'works', u'of', u'william', u'shakespeare', u',', u'by', u'william', u'shakespeare', u'this', u'ebook', u'is', u'for', u'the']\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from nltk import word_tokenize, Text\n",
    "text_string=codecs.open(\"shakespeare.txt\", \"r\", \"utf-8\").read() # Opens for reading and gets you the file content as a list\n",
    "text_string=text_string.lower()\n",
    "tokens = word_tokenize(text_string)\n",
    "print(type(tokens))\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "[u'\\ufeffthe', u'project', u'gutenberg', u'ebook', u'of', u'the', u'complete', u'works', u'of', u'william', u'shakespeare', u',', u'by', u'william', u'shakespeare', u'this', u'ebook', u'is', u'for', u'the', u'use', u'of', u'anyone', u'anywhere', u'at', u'no', u'cost', u'and', u'with', u'almost', u'no', u'restrictions', u'whatsoever', u'.', u'you', u'may', u'copy', u'it', u',', u'give', u'it', u'away', u'or', u're-use', u'it', u'under', u'the', u'terms', u'of', u'the']\n"
     ]
    }
   ],
   "source": [
    "text = Text(tokens)\n",
    "print(\"*\"*50)\n",
    "print(text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "william shakespeare; thou art; project gutenberg; illinois\n",
      "benedictine; machine readable; prohibited commercial; benedictine\n",
      "college; commercial distribution; distribution includes; copyright\n",
      "1990-1993; used commercially; king henry; complete works; gutenberg\n",
      "etext; electronic version; readable copies; others personal; personal\n",
      "use; world library; thou hast\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text.collocations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hamlet: Entire Play\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Tragedy of Hamlet, Prince of Denmark\n",
      "\n",
      "Shakespeare homepage \n",
      "    | Hamlet \n",
      "    | Entire play\n",
      "\n",
      "ACT I\n",
      "SCENE I. Elsinore. A platform before the castle.\n",
      "\n",
      "FRANCISCO at his post. Enter to him BERNARDO\n",
      "\n",
      "BERNARDO\n",
      "\n",
      "Who's there?\n",
      "\n",
      "FRANCISCO\n",
      "\n",
      "Nay, answer me: stand, and unfold you\n"
     ]
    }
   ],
   "source": [
    "# Fetching and cleaning a webpage:\n",
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"http://shakespeare.mit.edu/hamlet/full.html\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page.read())   \n",
    "raw = BeautifulSoup.get_text(soup)  \n",
    "print(raw[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'hamlet', u':', u'entire', u'play', u'the', u'tragedy', u'of', u'hamlet', u',', u'prince', u'of', u'denmark', u'shakespeare', u'homepage', u'|', u'hamlet', u'|', u'entire', u'play', u'act']\n"
     ]
    }
   ],
   "source": [
    "raw=raw.lower()\n",
    "tokens=nltk.word_tokenize(raw)\n",
    "print(tokens[:20])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
